# streamlit run rag_app.py ã§å®Ÿè¡Œå¯èƒ½

import streamlit as st
import os
import time
import pandas as pd
from dotenv import load_dotenv
from neo4j import GraphDatabase
from openai import OpenAI

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from processor import AdContentProcessor
from loader import load_to_neo4j, clear_ad_data
from mapper import map_associations_to_concepts

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()
NEO4J_URI = os.getenv("NEO4J_URI", "bolt://localhost:7687")
NEO4J_USER = os.getenv("NEO4J_USER", "neo4j")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")
AUTH = (NEO4J_USER, NEO4J_PASSWORD)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="Ad Risk Graph RAG Demo", layout="wide")

# --- ç”Ÿæˆæ©Ÿèƒ½ (Generation) ---

def generate_risk_explanation(input_text, risk_paths, era):
    """
    æ¤œç´¢ã•ã‚ŒãŸã‚°ãƒ©ãƒ•ãƒ‘ã‚¹(æ ¹æ‹ )ã«åŸºã¥ã„ã¦ã€ãƒªã‚¹ã‚¯ã®èª¬æ˜æ–‡ã‚’ç”Ÿæˆã™ã‚‹
    """
    if not risk_paths:
        return None

    client = OpenAI(api_key=OPENAI_API_KEY)

    # ã‚°ãƒ©ãƒ•ã®ãƒ‘ã‚¹æƒ…å ±ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåŒ–
    context_str = ""
    for i, path in enumerate(risk_paths):
        context_str += f"""
        [Path {i+1}]
        - è¡¨ç¾: {path['expression']}
        - é€£æƒ³: {path['association']}
        - æŠµè§¦æ¦‚å¿µ: {path['concept']} (å®šç¾©: {path['definition']})
        - ç‚ä¸Šè¦å› : {path['risk_label']}
        - é•åè¦ç¯„: {path['norm']}
        - å½±éŸ¿é›†å›£: {', '.join(path['affected_groups'])}
        """

    system_prompt = f"""
    ã‚ãªãŸã¯åºƒå‘Šãƒªã‚¹ã‚¯ç®¡ç†ã®å°‚é–€ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸåºƒå‘Šã‚³ãƒ”ãƒ¼ã«å¯¾ã—ã€çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‹ã‚‰æ¤œå‡ºã•ã‚ŒãŸã€Œãƒªã‚¹ã‚¯ã®æ ¹æ‹ ï¼ˆæ¨è«–ãƒ‘ã‚¹ï¼‰ã€ãŒæä¾›ã•ã‚Œã¾ã™ã€‚
    ã“ã‚Œã«åŸºã¥ãã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ‹…å½“è€…å‘ã‘ã®ã€Œãƒªã‚¹ã‚¯è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆã€ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

    ã€åˆ¶ç´„äº‹é …ã€‘
    1. æä¾›ã•ã‚ŒãŸ[Path]æƒ…å ±ã®ã¿ã‚’æ ¹æ‹ ã«ã—ã¦ãã ã•ã„ï¼ˆãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ç¦æ­¢ï¼‰ã€‚
    2. åˆ¤å®šåŸºæº–ã®æ™‚ä»£ã¯ã€Œ{era}ã€ã§ã™ã€‚ãã®æ™‚ä»£ã®ä¾¡å€¤è¦³ã«æ²¿ã£ã¦è§£èª¬ã—ã¦ãã ã•ã„ã€‚
    3. çµè«–ã‚’å…ˆã«è¿°ã¹ã€ãã®å¾Œã«å…·ä½“çš„ãªç†ç”±ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
    4. ãƒˆãƒ¼ãƒ³ã¯å®¢è¦³çš„ã‹ã¤è«–ç†çš„ã«ã€‚
    """

    user_prompt = f"""
    ã€å¯¾è±¡åºƒå‘Šã‚³ãƒ”ãƒ¼ã€‘
    {input_text}

    ã€æ¤œå‡ºã•ã‚ŒãŸãƒªã‚¹ã‚¯ãƒ‘ã‚¹ï¼ˆæ ¹æ‹ ï¼‰ã€‘
    {context_str}

    ä¸Šè¨˜ã«åŸºã¥ãã€ã“ã®åºƒå‘ŠãŒãªãœç‚ä¸Šãƒªã‚¹ã‚¯ã‚’æŒã¤ã®ã‹ã€å…·ä½“çš„ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.0
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error generating explanation: {e}"

# --- æ¤œç´¢æ©Ÿèƒ½ (Retrieval) ---

def get_risk_analysis(driver, ad_id, era):
    """
    æŒ‡å®šã•ã‚ŒãŸæ™‚ä»£(era)ã«åŸºã¥ã„ã¦ãƒªã‚¹ã‚¯ãƒ‘ã‚¹ã‚’æ¢ç´¢ã™ã‚‹
    (ä¿®æ­£: Normã‚„GroupãŒæ¬ ã‘ã¦ã„ã¦ã‚‚ãƒ‘ã‚¹ã‚’è¡¨ç¤ºã™ã‚‹ã‚ˆã†ã«OPTIONAL MATCHåŒ–)
    """
    query = """
    MATCH (ad:Ad {id: $ad_id})
    // 1. åºƒå‘Šè¡¨ç¾ã‹ã‚‰é€£æƒ³ã¸ (å¿…é ˆ)
    MATCH (ad)-[:HAS_EXPRESSION]->(expr:Expression)-[:EVOKES]->(assoc:Association)
    
    // 2. é€£æƒ³ã‹ã‚‰æ¦‚å¿µã¸ (å¿…é ˆ: ã“ã“ãŒåˆ‡ã‚Œã¦ã„ã‚Œã°ãƒªã‚¹ã‚¯ãªã—åˆ¤å®šã§æ­£ã—ã„)
    MATCH (assoc)-[link:MAPS_TO|CANDIDATE_OF]->(concept:Concept)
    
    // 3. æ¦‚å¿µã‹ã‚‰ãƒªã‚¹ã‚¯è¦å› ã¸ (å¿…é ˆ: ã“ã“ã¾ã§ç¹‹ãŒã‚Œã°ã€Œãƒªã‚¹ã‚¯ã‚ã‚Šã€ã¨ã¿ãªã™)
    MATCH (concept)-[:LEADS_TO]->(risk:RiskFactor)

    // 4. æ™‚ä»£ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    WHERE (concept.valid_eras IS NULL OR $era IN concept.valid_eras)

    // --- ä¿®æ­£ç®‡æ‰€: ã“ã“ã‹ã‚‰ä¸‹ã‚’ OPTIONAL MATCH ã«å¤‰æ›´ ---
    // è¦ç¯„ã‚„å½±éŸ¿é›†å›£ãŒæœªå®šç¾©ã§ã‚‚ã€RiskFactorã¾ã§åˆ°é”ã—ã¦ã„ã‚Œã°è¡¨ç¤ºã™ã‚‹
    
    OPTIONAL MATCH (risk)-[:VIOLATES]->(norm:Norm)
    OPTIONAL MATCH (risk)-[:OFFENDS]->(group:AffectedGroup)
    
    RETURN 
        expr.text as expression,
        assoc.name as association,
        type(link) as link_type,
        link.similarity as similarity,
        concept.name as concept,
        concept.definition as definition,
        risk.label as risk_label,
        // normã‚„groupãŒãªã„å ´åˆã¯ã€Œæœªå®šç¾©ã€ç­‰ã®æ–‡å­—åˆ—ã‚’è¿”ã™ã‚ˆã†Coalesceã™ã‚‹
        coalesce(norm.name, "è¦ç¯„å®šç¾©ãªã—") as norm,
        collect(DISTINCT group.name) as affected_groups
    ORDER BY risk_label
    """
    with driver.session() as session:
        result = session.run(query, ad_id=ad_id, era=era)
        return [record.data() for record in result]

# --- ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ---

def main():
    st.title("ğŸ›¡ï¸ Ad Risk Analysis System (Graph RAG)")
    st.markdown("è«–æ–‡ã€ŒGraph RAGã‚’ç”¨ã„ãŸåºƒå‘Šç‚ä¸Šãƒªã‚¹ã‚¯ã®åˆ†æã€ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ Settings")
        selected_era = st.selectbox("ğŸ“… åˆ¤å®šåŸºæº–ã®æ™‚ä»£ (Era)", ["2020s", "2010s"], index=0)
        st.divider()
        show_debug = st.checkbox("Show Graph Payload", value=False)
        if st.button("Clear Cache & Data"):
            clear_ad_data()
            st.success("Ad data cleared.")

    # å…¥åŠ›ã‚¨ãƒªã‚¢
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("1. Input Ad Copy")
        default_text = "å®¶äº‹ã¯ãƒãƒã®ä»•äº‹ã€ãŒã‚“ã°ã£ã¦ã€‚å®¶æ—ã®ãŸã‚ã«ã€‚"
        input_text = st.text_area("åºƒå‘Šã‚³ãƒ”ãƒ¼ã‚’å…¥åŠ›", value=default_text, height=150)
        analyze_btn = st.button("ğŸ” Analyze Risk", type="primary")

    if analyze_btn and input_text:
        status_text = st.empty()
        progress_bar = st.progress(0)

        try:
            # --- Step 1: Processor ---
            processor = AdContentProcessor()
            status_text.text("Step 1/3: Extracting facts from text (LLM)...")
            progress_bar.progress(30)
            
            meta = {"csv_id": "DEMO_APP", "brand": "DemoBrand"}
            payload = processor.analyze_ad_content(input_text, meta)
            ad_id = payload['ad_id']
            
            if show_debug:
                with col1:
                    st.json(payload)

            # --- Step 2: Loader ---
            status_text.text("Step 2/3: Loading structure to Knowledge Graph...")
            progress_bar.progress(60)
            load_to_neo4j(payload)

            # --- Step 3: Mapper ---
            status_text.text("Step 3/3: Inferring semantic connections (Vector Search)...")
            progress_bar.progress(80)
            map_associations_to_concepts()
            
            progress_bar.progress(100)
            status_text.text("Analysis Complete.")
            time.sleep(0.5)
            status_text.empty()
            progress_bar.empty()

            # --- Step 4: Graph RAG (Retrieve & Generate) ---
            driver = GraphDatabase.driver(NEO4J_URI, auth=AUTH)
            results = get_risk_analysis(driver, ad_id, selected_era)
            driver.close()

            with col2:
                st.subheader(f"2. Analysis Results ({selected_era})")
                
                if not results:
                    st.success("âœ… No significant risks detected in this era.")
                    st.info("â€» æ™‚ä»£è¨­å®šã‚’å¤‰ãˆã‚‹ã¨ãƒªã‚¹ã‚¯ãŒæ¤œçŸ¥ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                else:
                    # --- è¿½åŠ æ©Ÿèƒ½: ç”Ÿæˆã•ã‚ŒãŸãƒªã‚¹ã‚¯èª¬æ˜ã®è¡¨ç¤º ---
                    st.markdown("### ğŸ“ AI Risk Assessment")
                    with st.spinner("Generating explanation..."):
                        explanation = generate_risk_explanation(input_text, results, selected_era)
                        st.info(explanation)

                    # --- æ—¢å­˜æ©Ÿèƒ½: è©³ç´°ãƒ‘ã‚¹ã®è¡¨ç¤º ---
                    st.markdown("### ğŸ” Evidence Paths (Graph Trace)")
                    df = pd.DataFrame(results)
                    for risk_label in df['risk_label'].unique():
                        st.write(f"**ğŸ”¥ {risk_label}**")
                        subset = df[df['risk_label'] == risk_label]
                        for _, row in subset.iterrows():
                            with st.expander(f"è¡¨ç¾: ã€Œ{row['expression']}ã€ â†’ æ¦‚å¿µ: {row['concept']}"):
                                st.markdown(f"""
                                - **é€£æƒ³**: {row['association']}
                                - **æŠµè§¦ã—ãŸæ¦‚å¿µ**: {row['concept']}
                                  - å®šç¾©: *{row['definition']}*
                                - **é•åè¦ç¯„**: {row['norm']}
                                - **å½±éŸ¿é›†å›£**: {', '.join(row['affected_groups'])}
                                - **åˆ¤å®šã‚¿ã‚¤ãƒ—**: {row['link_type']} (Similarity: {row['similarity']:.3f})
                                """)

        except Exception as e:
            st.error(f"Error occurred: {e}")

    st.markdown("---")
    st.markdown("### ğŸ“Š System Logic")
    st.caption("""
    1. **Fact Extraction**: åºƒå‘Šæ–‡ã‹ã‚‰äº‹å®Ÿã‚’æŠ½å‡º
    2. **Graph Mapping**: ç¤¾ä¼šçš„æ¦‚å¿µã¸æ¥ç¶š
    3. **Path Finding**: ç‚ä¸Šãƒ‘ã‚¹ã‚’æ¢ç´¢
    4. **Explanation**: æ ¹æ‹ ãƒ‘ã‚¹ã«åŸºã¥ãè§£èª¬ã‚’ç”Ÿæˆ
    """)

if __name__ == "__main__":
    main()